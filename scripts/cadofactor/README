The cadofactor Python script is generally run with

./cadofactor.py parameterfile

All the parameters for the factorization are read from the parameter file,
but it is possible to specify such parameters on the command line, after
parameterfile.

For example, running

./cadofactor.py ../../params/params.c59 N=90377629292003121684002147101760858109247336549001090677693 tasks.workdir=/tmp/c59 tasks.execpath=$HOME/build/cado-nfs/normal server.whitelist=0.0.0.0/0

starts the cadofactor script, which also starts the server. It does not start any clients with this command line, so those would have to be started manually:

./wuclient2.py --server=https://quiche.loria.fr:8001 --certsha1=[Certificate SHA1]

where the --server and --certsha1 parameters should be given the URL and certificate SHA1 value of the server,
respectively, as printed by the cadofactor script. You can start an arbitrary number of client scripts, on any
machines that can connect to the server via HTTP.

If you want to let the server automatically start clients, you need to supply a list of hostnames on which to start clients, e.g.,

./cadofactor.py ../../params/params.c59 N=90377629292003121684002147101760858109247336549001090677693 tasks.workdir=/tmp/c59 tasks.execpath=$HOME/build/cado-nfs/normal slaves.hostnames=localhost slaves.nrclients=2 slaves.scriptpath=$HOME/git/cado-nfs/scripts/cadofactor

to let it start two clients on localhost. The scriptpath parameter must be the path to the directory on the client machine which contains wuclient2.py (and workunit.py).


For complex set-ups, it is preferable to write a parameter file. Some examples are in "parameters", "parameters.oar", and "parameters.rsa512.oar".

The .oar parameter files are meant for cadofactor scripts that run *inside* an OAR submission on clusters that use OAR as the job scheduler,
such as Grid5000, as they read the list of slave hostnames from the OAR node file.

For example,

oarsub -I
./cadofactor.py parameters.oar

factors the usual c59 test number using the nodes reserved via OAR, in this case one node.
The parameters.oar file contains the line
slaves.catrel.nrclients = 8
which tells the script to launch 8 clients on each unique host name (=node); the parameter
threads=2
causes all the programs to use two threads, resulting in 16 threads per node.

Importing a polynomial file
===========================

If you want to import a polynomial file (either an SNFS polynomial, or
if polynomial selection was already done), use:

tasks.polyselect.import=xxx.poly

where xxx.poly is the name of the polynomial file (in CADO-NFS format).

This imports the polynomial and then performs any polynomial selection
specified in the parameter file; the best polynomial (rated by the Murphy E
value) will be used for the sieving. If you want to use the imported
polynomial without any additional polynomial search, set a zero-sized search
range for polynomial selection:

tasks.polyselect.admin=0
tasks.polyselect.admax=0

Note that this empty search range must be specified even after interrupting
and restarting cadofactor to prevent it from running polynomial selection;
if after interruption a larger admax is given, cadofactor will perform
polynomial search from the point where it left off (i.e., from ad=0) up to
the new upper limit, admax.

The polynomial selection run by cadofactor is performed in two phases:
the first phase searches for polynomials with good size property and keeps
in a priority queue the "nrkeep" most promising ones, then the second phase
root-optimizes these to find the overall best polynomial.

Care should be taken when trying to import size-optimized polynomials into
phase 1's priority queue (so that they will be forwarded to the second
phase). It is advisable to give the full parameter path to the "import"
statement, so that the polynomials aren't misinterpreted as being both
size- and root-optimized already. E.g., write

tasks.polyselect.polyselect1.import = size_optimized_polynomials.txt

(and not just tasks.polyselect.import = ...) to import them to phase 1's
priority queue, so that phase 2 will later root-optimize them.

To import polynomials that are fully optimized already (as produced by an
earlier factorization, or an SNFS polynomials), it is sufficient to use

tasks.polyselect.import = polynomial.txt

If the polynomial in the polynomial.txt file does not specify a "lognorm",
it is simply ignored by the first phase and does not get added to the
priority queue, but is imported as an already optimized polynomial into
the second phase.


Importing relations
===================

If you want to import already computed relations, use:

tasks.sieve.import=foo

where "foo" is the name of the relation file to be imported (in CADO-NFS
format). Alternatively you can do:

tasks.sieve.import=@foo

where "foo" is a file containing several names of relation files, one file
name per line.

Adjust the tasks.sieve.sieving.qmin parameter accordingly to prevent
already-sieved special-q ranges from being sieved again.

File locking
============

The SqLite database used by cadofactor makes extensive use of file locking.
This requires that the underlying file system properly implements POSIX file
locking. One example of a file system that claims to, but does not, is
glusterfs, which leads to random SqLite errors. See the thread

http://gluster.org/pipermail/gluster-users/2011-September/031720.html

If you encounter "Database corrupted" or similar errors, try if storing the
working directory on a local (not network-mounted) file system resolves the
problem.

Controlling the excess
======================

By default CADO-NFS requires an excess (after the first singleton removal)
of 10% more relations than ideals. This is controlled by:

tasks.filter.purge.required_excess=0.1

If you want a larger excess, say 20%, just add on the cadofactor.py command
line (or in the parameter file):

tasks.filter.purge.required_excess=0.2

If any positive excess is enough:

tasks.filter.purge.required_excess=0.0
