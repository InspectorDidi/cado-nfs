# Redoing the experiments concerning the accuracy
## A: level 2: bench(2^14, 2, 2^6, 4, ((-1, 1), (-1, 1), (-1, 1), (-1, 1)), ((-2, 2), (-2, 2), (-1, 1), (-1, 1)), ())
## A: level 3: bench(2^14, 3, 2^6, 4, ((-1, 1), (-1, 1), (-1, 1), (-1, 1)), (), ())
## B: bench(2^7, 2, 2^4, 6, ((-1, 1), (-1, 1), (-1, 1), (-1, 1), (-1, 1), (-1, 1)), ((-1, 1), (-1, 1), (-1, 1), (-1, 1), (-1, 1), (-1, 1)), ((-1, 1), (-1, 1), (-1, 1), (-1, 1), (-1, 1), (-1, 1)))
## C: bench(2^7, 3, 2^4, 6, ((-1, 1), (-1, 1), (-1, 1), (-1, 1), (-1, 1), (-1, 1)), ((-1, 1), (-1, 1), (-1, 1), (-1, 1), (-1, 1), (-1, 1)), ((-1, 1), (-1, 1), (-1, 1), (-1, 1), (-1, 1), (-1, 1)))
## D at level 4: bench(2^7, 4, 2^4, 6, ((-1, 1), (-1, 1), (-1, 1), (-1, 1), (-1, 1), (-1, 1)), ((-1, 1), (-1, 1), (-1, 1), (-1, 1), (-1, 1), (-1, 1)), ())
## D at level 5: bench(2^7, 5, 2^4, 6, ((-1, 1), (-1, 1), (-1, 1), (-1, 1), (-1, 1), (-1, 1)), (), ())

# Benchmarks for the running time
# bench_time_l2(1024, 2^6, 4, ((-1, 1), (-1, 1), (-1, 1), (-1, 1)), ((-2, 2), (-2, 2), (-1, 1), (-1, 1)), seed=42)
# bench_time_l3(1024, 2^6, 4, ((-1, 1), (-1, 1), (-1, 1), (-1, 1)), ((-2, 2), (-2, 2), (-1, 1), (-1, 1)), seed=42)

import time

"""
When a matrix represents a lattice, the lattice is generated by the row vector of the matrix.
A search space is given by ((H0m, H0M), (H1m, H1M), ..., (H(t-1)m, H(t-1)M).
"""

################################################################################
### Utils
################################################################################
# Generate a matrix which can be the one of an ideal
# [r 0 0]
# [a 1 0]
# [b 0 1]
def gen_matrix(t, r):
    M = [[0 for i in range(0, t)] for j in range(0, t)]
    M[0][0] = r # lattice of volume r
    for i in range(1, t):
        M[i][0] = ZZ.random_element(0, r) # random element less than r in the first column
        M[i][i] = 1 # diagonal element
    return matrix(M)

# Remove duplicate vectors in a list
def remove_duplicate(L):
    # Convert vector to tuple
    Lt = [tuple(i) for i in L]
    # Remove duplicate with set and reconvert Lt to a list
    Lt = list(set(Lt))
    # Return a list of vector, since in Lt, the elements are tuples
    return [vector(i) for i in Lt]

# Size of the search space H
def size_H(H):
    size = 1
    for i in H:
        size = size * (i[1] - i[0])
    return size

# Verify if the vector v is in the lattice described by B (works only when B is square)
def in_lattice(v, B):
    x = v * B^(-1)
    for i in x:
        if i != ceil(i):
            return False
    return True

# Add one to a in bound to give another a in bound
# Ex: bound = ((-2, 1), (-2, 1), (0, 2)) and a = (-1, 1, 0)
#     1st call returns (0, 1, 0)
#     2nd call returns (1, 1, 0)
#     3rd call returns (-2, -2, 1)
# Ex: bound = ((-2, 1), (-2, 1), (0, 2)) and a = (-1, 1, 2)
#     1st call returns (0, 1, 2)
#     2nd call returns (1, 1, 2)
#     3rd call returns an exception (not possible to add one and keep in bound)
# a must support item assignment (e.g., be a list)
def add_one(a, bound):
    k = 0
    while k < len(bound):
        if a[k] == bound[k][1]:
            a[k] = bound[k][0]
            k = k + 1;
        else:
            break
    if k < len(bound):
        a[k] = a[k] + 1
    else:
        # Out of the bounds
        raise Exception()

# Sort by coordinate k the vectors of L
# Assume that in L, all the vectors are k-skew-small vectors (i.e., v[k] > 0)
def sort_by_coordinate(L, k):
    if len(L) == 0:
        return []
    else:
        # Create a list indexed by the value of v[k]
        # TODO: sort can be initialized with [] instead of 0. It will simplify the rest of the code.
        sort = [0 for i in range(max([v[k] for v in L]) + 1)]
        for v in L:
            if sort[v[k]] == 0:
                # First vector with such a coordinate v[k]
                sort[v[k]] = [v]
            else:
                sort[v[k]].append(v)
        # l is similar to sort, instead that empty list (i.e., element 0 in sort) are not retuned
        l = []
        for i in sort:
            if i != 0:
                for v in i:
                    l.append(v)
        return l

################################################################################
### Utils for skew small and nearly transition vectors
################################################################################
# Find in which kth list we need to store a vector
def type_V(v):
    i = len(v) - 1
    while i >= 0:
        if v[i] != 0:
            return i
        i = i - 1
    return i

# True if v is a nearly transition vector
def good_V(v, H):
    if v[type_V(v)] < 0:
        return False
    for i in range(0, len(v)):
        if abs(v[i]) >= (H[i][1] - H[i][0]):
            return False
    return True

# Store v in the skew small transition vector list or the nearly transition vector list (do not take care of the k of the k-*-transition vector)?
def in_V_or_S(v, H, V, S):
    # FIXME: why gcd = 1? A vector can be in the lattice whithout gcd = 1.
    # FIXME: checking for type_V(v) is probably always False.
    if gcd(list(v)) == 1 or type_V(v) == 0:
        if good_V(v, H):
            V.append(v)
        S.append(v)

# v in H?
def in_search_space(v, H):
    for i in range(len(v)):
        if H[i][0] > v[i] or v[i] >= H[i][1]:
            return False
    return True

# v in H_k?
def in_extended_search_space(v, H, k):
    for i in range(k + 1):
        if H[i][0] > v[i] or v[i] >= H[i][1]:
            return False
    return True

################################################################################
### Lattice algorithms
################################################################################
# Find closest vectors around v in the lattice described by M
# BEWARE: M must be lower triangular, that is the last coordinates of vectors of M must be 0
def CVA(v, M):
    dim = M.dimensions()[0]
    V = []
    # Solve CVP in dimension 1
    if dim == 1:
        k = floor(v[0] / M[0][0])
        V.append(k * M.rows()[0])
        if v[0] - V[0][0] > 0:
            V.append((k + 1) * M.rows()[0])
        else:
            V.append((k - 1) * M.rows()[0])
    # Solve CVP in dimension > 1
    else:
        L = []
        # Extract the upper square part of M and perform a lattice reduction on it
        Me = M.submatrix(0, 0, dim, dim).LLL()
        bound = []
        # Babai rounding to define a region around the closest vector of v
        for k in v[0:dim] * Me^(-1):
            bound.append((floor(k), ceil(k)))
        # In the following, a is a vector close to v[0:dim] in Me
        a = [h[0] for h in bound]
        L.append(vector(a) * Me)
        # FIXME: a bit ugly, do all the possible linear combination and wait until add_one return an exception
        while 1:
            try:
                add_one(a, bound)
                L.append(vector(a) * Me)
            except Exception:
                break
        # Complete the last coordinates of all the vector in L by 0 to be closest vectors to v in M
        for v in L:
            v = list(v)
            for k in range(dim, M.dimensions()[1]):
                v.append(0)
            V.append(vector(v))

    return V

# Franke Kleinjung algorithm
# See the implementation of FK in the file sieve/las-plattice.hpp (reduce_plattice in commit 926773c93e)
# Lattice is of the form (dim = 4 here)
# [r 0 0 0]
# [h 1 0 0]
# [a 0 1 0]
# [b 0 0 1]
# r must be larger than I, I is often equal to H0M - H0m
# Return [None, None, None] if the algorithm failed
def reduce_qlattice(r, h, I, dim = 2):
    assert(r.is_prime())
    assert(dim >= 2)

    a0 = -r; b0 = h; a1 = 0; b1 = 1; k = 0
    hI = I; mhI = -hI;

    while b0 >= hI:
        k = int(float(a0) / float(b0))
        if bool(a0 < 0) != bool(b0 < 0):
            a0 = a0 % b0
            a0 = a0 - b0
        else:
            a0 = a0 % b0
        a1 = a1 - k * b1;
        if a0 > mhI:
            break;
        k = int(float(b0) / float(a0))
        if bool(a0 < 0) != bool(b0 < 0):
            b0 = b0 % a0
            b0 = b0 - a0
        else:
            b0 = b0 % a0
        b1 = b1 - k * a1;
        if b0 < hI:
            break
        k = int(float(a0) / float(b0))
        if bool(a0 < 0) != bool(b0 < 0):
            a0 = a0 % b0
            a0 = a0 - b0
        else:
            a0 = a0 % b0
        a1 = a1 - k * b1;
        if a0 > mhI:
            break
        k = int(float(b0) / float(a0))
        if bool(a0 < 0) != bool(b0 < 0):
            b0 = b0 % a0
            b0 = b0 - a0
        else:
            b0 = b0 % a0
        b1 = b1 - k * a1;
    k = b0 - hI - a0;
    if b0 > -a0:
        if a0 == 0:
            return [None, None, None]
        k = int(float(k )/ float(a0))
        b0 = b0 - k * a0
        b1 = b1 - k * a1;
    else:
        if b0 == 0:
            return [None, None, None]
        k = int(float(k )/ float(b0))
        a0 = a0 + k * b0
        a1 = a1 + k * b1;
    assert(a0 > mhI); assert(0 >= a0); assert(0 <= b0); assert(b0 < hI); assert(a1 > 0); assert(b1 > 0)

    u = vector([a0, a1] + [0 for i in range(dim - 2)])
    v = vector([b0, b1] + [0 for i in range(dim - 2)])
    return (u, v, u + v)

# Skew LLL of B for localntv and sparsentv, since it fall back to Franke-Kleinjung algorithm if l=1 or do nothing if l=0
# Lattice is of the form (dim = 4 here)
# [r 0 0 0]
# [h 1 0 0]
# [a 0 1 0]
# [b 0 0 1]
# Let v a basis vector of M at index <= l, for all k, v[k] must be close to L[k]
# In addition, the last non-zero coordinate coordinate of all v must be positive
def skew_LLL_FK(B, L, l):
    if l == 0:
        # Basis is reduced
        return B
    elif l == 1:
        # Apply FK algorithm
        (u, v, w) = reduce_qlattice(B[0][0], B[1][0], L[0], B.dimensions()[0])
        if w == None:
            # FK fails, fall-back to the original basis
            return B
        else:
            # Returns the matrix with the two first vectors FK reduced and the last vector of the basis
            return matrix([u, v] + B.rows()[2:B.dimensions()[0]])
    else:
        Lr = [1/k for k in L]
        # Extract the part of the matrix we want to reduce
        M = B.submatrix(0, 0, l + 1, l + 1)
        I = diagonal_matrix(Lr[0:l + 1])
        # Shift a matrix by multiplying the row k by 1/L[k]
        MS = (M * I)
        # Get the unimodular matrix that modify MS in MS.LLL()
        U = MS.LLL() * MS**(-1)
        assert(abs(U.determinant()) == 1)
        # Apply the unimodular matrix on the original matrix M to build the skew reduced matrix MSLLL
        MSLLL = U * M

        # C is the list of coefficients B
        C = [list(k) for k in B.rows()]
        # Replace the coefficient of the square subpart of C by the one of MSLLL
        for k in range(0, l + 1):
            for j in range(0, l + 1):
                C[k][j] = MSLLL[k][j]
        # Lr will be now used to modify the last non-zero coordinate coordinate if negative
        Lr = []
        for k in range(0, l + 1):
            # TODO: can be done with type_V (see skew_LLL below)
            if sign(C[k][l]) != 0:
                Lr.append(sign(C[k][l]))
            else:
                j = l - 1
                while sign(C[k][j]) == 0:
                    j = j - 1
                Lr.append(sign(C[k][j]))
        for k in range(l + 1, B.dimensions()[1]):
            Lr.append(1)

        # TODO: maybe matrix(C) instead of matrix(B.dimensions()[0], B.dimensions()[1], C) is sufficient
        C = diagonal_matrix(Lr) * matrix(B.dimensions()[0], B.dimensions()[1], C)
        # Verify that the volume of the lattice is the same of the original lattice (do not imply that the lattice are the same, but it helps)
        assert(abs(C.determinant()) == abs(B.determinant()))
        return C

# Skew LLL of M according to L
# Let v a basis vector of M, for all k, v[k] must be close to L[k]
# In addition, the last non-zero coordinate coordinate of v must be positive
def skew_LLL(M, L):
    Lr = [1/k for k in L]
    I = diagonal_matrix(Lr)
    # Shift a matrix by multiplying the row k by 1/L[k]
    MS = (M * I)
    # Get the unimodular matrix that modify MS in MS.LLL()
    U = MS.LLL() * MS^(-1)
    # Verify that the matrix is unimodular
    assert(abs(U.determinant()) == 1)
    # Apply the unimodular matrix on the original matrix M to build the skew reduced matrix MSLLL
    MSLLL = U * M
    vec = []
    # Modify the basis vector if the last non-zero coordinate coordinate is negative
    for v in list(MSLLL):
        if v[type_V(v)] < 0:
            vec.append(-v)
        else:
            vec.append(v)
    return matrix(vec)

################################################################################
### NTV algorithms
################################################################################
# Do small linear combinations depending on bound of vector of B and return list of ssvs or ntvs according to H
# Ex of bound
  # e.g.: ((-2, 2), (-2, 2), (-1, 1), (-1, 1))
def small_linear_comb(bound, B, H):
    # nearly transition vectors
    V = []
    # skew small vectors
    S = []
    a = [h[0] for h in bound]
    n = len(bound)
    v = vector([0 for i in range(len(H))])
    # v is a linear combination of the vector of B
    for i in range(len(a)):
        v = v + a[i] * B[i]
    if v[type_V(v)] < 0:
        # The coordinate v[type_V(v)] must be positive (i.e., if v is a k-nearly transition vector, v[k] must be > 0)
        v = -v
    in_V_or_S(v, H, V, S)
    # FIXME: a bit ugly, do all the possible linear combination and wait until add_one return an exception
    while 1:
        try:
            add_one(a, bound)
            v = vector([0 for i in range(len(H))])
            for i in range(len(a)):
                v = v + a[i] * B[i]
            if v[type_V(v)] < 0:
                v = -v
            in_V_or_S(v, H, V, S)
        except Exception:
            break
    return (V, S)

# Build skew-small-vectors for globalntv
# M: matrix that represents an ideal
# H: search space
# l: level
# bound: bounds of the small linear combination
def global_ssv(M, H, l, bound):
    t = len(H)
    V = [[] for k in range(t)]
    S = [[] for k in range(t)]
    Vt = []
    St = []

    # Define the bound for the skew LLL
    L = []
    for k in range(0, l):
        L.append(H[k][1] - H[k][0])
    L.append(ceil(M.determinant() / prod(L)))
    for k in range(l + 1, t):
        L.append(1)

    # Generate the ssvs and ntvs (skew LLL + small linear combinations)
    MSLLL = skew_LLL(M, L)
    (Vt, St) = small_linear_comb(bound, MSLLL, H)
    Vt = remove_duplicate(Vt)
    St = remove_duplicate(St)

    # Store the k-* vectors in the corresponding list
    for v in Vt:
        V[type_V(v)].append(v)
    for v in St:
        S[type_V(v)].append(v)

    # Sort by increasing coordinate k
    for k in range(0, t):
        V[k] = sort_by_coordinate(V[k], k)
        S[k] = sort_by_coordinate(S[k], k)

    return V, S

# Build skew-small-vectors for localntv
# M: matrix that represents an ideal
# H: search space
# l: level
def local_ssv(M, H, l, bound):
    t = len(H)
    V = [[] for k in range(t)]
    S = [[] for k in range(t)]
    Vt = []
    St = []
    if l == 0:
        in_V_or_S(M[0], H, V[0], S[0])
        # Test if the vectors used basically by the line sieve are nearly transition vectors
        for k in range(1, M.dimensions()[0]):
            in_V_or_S(M[k], H, V[k], S[k])
            in_V_or_S(M[k] - M[0], H, V[k], S[k])
    else:
        # Compute the form which coordinate the basis vectors given by skew_LLL must be
        L = []
        for k in range(0, l):
            L.append(H[k][1] - H[k][0])
        L.append(ceil(M.determinant() / prod(L)))
        for k in range(l + 1, t):
            L.append(1)

        MSLLL = skew_LLL_FK(M, L, l)
        # FK algorithm was called
        if l == 1:
            u = MSLLL.rows()[0]
            v = MSLLL.rows()[1]
            # FK algorithm fails
            if u[1] == 0 and v[1] == 1:
                in_V_or_S(u, H, V[0], S[0])
                in_V_or_S(v, H, V[1], S[1])
            else:
                in_V_or_S(u, H, V[1], S[1])
                in_V_or_S(v, H, V[1], S[1])
                in_V_or_S(u + v, H, V[1], S[1])

        else:
            (Vt, St) = small_linear_comb(bound[0:l + 1], MSLLL.submatrix(0, 0,
                l + 1, M.dimensions()[1]), H)
            Vt = remove_duplicate(Vt)
            St = remove_duplicate(St)

        for v in Vt:
            V[type_V(v)].append(v)
        for v in St:
            S[type_V(v)].append(v)

        # Generate the constraint vectors
        for k in range(l + 1, t):
            e = MSLLL.row(k)
            D = CVA(e, M.submatrix(0, 0, k, M.dimensions()[1]))
            for d in D:
                in_V_or_S(e - d, H, V[k], S[k])

    for k in range(0, t):
        V[k] = sort_by_coordinate(V[k], k)
        S[k] = sort_by_coordinate(S[k], k)

    return V, S

# Build skew-small-vectors for sparsentv
def sparse_ssv(M, H, l, bound):
    t = len(H)
    V = [[] for k in range(t)]
    S = [[] for k in range(t)]
    Vt = []
    St = []
    if l == 0:
        in_V_or_S(M[0], H, V[0], S[0])
        # Test if the vectors used basically by the line sieve are nearly transition vectors
        for k in range(1, M.dimensions()[0]):
            in_V_or_S(M[k], H, V[k], S[k])
            in_V_or_S(M[k] - M[0], H, V[k], S[k])
    else:
        # Compute the form which coordinate the basis vectors given by skew_LLL must be
        L = []
        for k in range(0, l):
            L.append(H[k][1] - H[k][0])
        L.append(ceil(M.determinant() / prod(L)))
        for k in range(l + 1, t):
            L.append(1)

        MSLLL = skew_LLL_FK(M, L, l)
        # FK algorithm was called
        if l == 1:
            u = MSLLL.rows()[0]
            v = MSLLL.rows()[1]
            if u[1] == 0 and v[1] == 1:
                in_V_or_S(u, H, V[0], S[0])
                in_V_or_S(v, H, V[1], S[1])
            else:
                in_V_or_S(u, H, V[1], S[1])
                in_V_or_S(v, H, V[1], S[1])
                in_V_or_S(u + v, H, V[1], S[1])

        else:
            (Vt, St) = small_linear_comb(bound[0:l + 1], MSLLL.submatrix(0, 0,
                l + 1, M.dimensions()[1]), H)
            Vt = remove_duplicate(Vt)
            St = remove_duplicate(St)

        for v in Vt:
            V[type_V(v)].append(v)
        for v in St:
            S[type_V(v)].append(v)

        # Generate the constraint vectors
        for k in range(l + 1, t):
            e = MSLLL.row(k)
            D = CVA(e, M.submatrix(0, 0, l + 1, M.dimensions()[1]))
            for d in D:
                in_V_or_S(e - d, H, V[k], S[k])

    for k in range(0, t):
        V[k] = sort_by_coordinate(V[k], k)
        S[k] = sort_by_coordinate(S[k], k)

    return V, S

# Add to c a vector of V[k] if possible, fall-back with S otherwise
def sieve(k, c, H, V, S, L, l, M, fb):
    ct = copy(c)
    while ct[k] < H[k][1]:
        if in_search_space(ct, H):
            L.append(ct)
        if k > 0:
            sieve(k - 1, ct, H, V, S, L, l, M, fb)
        ct = add(k, ct, H, V, S, l, M, fb)
    ct = copy(c)
    ct = sub(k, ct, H, V, S, l, M, fb)
    if in_search_space(ct, H):
        L.append(ct)
    while ct[k] >= H[k][0]:
        if k == 0 and in_search_space(ct, H):
            L.append(ct)
        if k > 0 :
            sieve(k - 1, ct, H, V, S, L, l, M, fb)
        ct = sub(k, ct, H, V, S, l, M, fb)

# Add to c a vector of V[k] if possible, repair with S otherwise
def add(k, c, H, V, S, l, M, fb):
    for v in V[k]:
        if in_extended_search_space(c + v, H, k - 1):
            return c + v
    d = 0
    # Call to the fall-back strategy
    if k > l or (k == len(H) - 1):
        d = fb_add(k, c, H, S, M, fb)
        if in_search_space(d, H):
            V[k].append(d - c)
            S[k].append(d - c)
            V[k] = sort_by_coordinate(V[k], k)
            S[k] = sort_by_coordinate(S[k], k)
    else:
        d = vector([h[1] for h in H])
    return d

# Subtract to c a vector of V[k] if possible, repair with S otherwise
def sub(k, c, H, V, S, l, M, fb):
    for v in V[k]:
        if in_extended_search_space(c - v, H, k - 1):
            return c - v
    d = 0
    # Call to the fall-back strategy
    if k > l or (k == len(H) - 1):
        d = fb_sub(k, c, H, S, M, fb)
        if in_search_space(d, H):
            V[k].append(c - d)
            S[k].append(c - d)
            V[k] = sort_by_coordinate(V[k], k)
            S[k] = sort_by_coordinate(S[k], k)
    else:
        d = vector([h[0] - 1 for h in H])
    return d

# Find a new element from c at step k, in the lattice generated by M (fall-back strategy), additive case
# S is the list of skew small vectors, fb is incremented at each call to the while loop
def fb_add(k, c, H, S, M, fb):
    ct = copy(c)
    while ct[k] < H[k][1]:
        fb[0] = fb[0] + 1
        L = []
        for v in S[k]:
            if k != 0:
                D = CVA(ct + v, M.submatrix(0, 0, k, M.dimensions()[0]))
                for d in D:
                    L.append(ct + v - d)
                    if in_search_space(ct + v - d, H):
                        return ct + v - d
        if len(L) == 0:
            break
        else:
            ct = L[0]
    return vector([h[1] for h in H])

# Find a new element from c at step k, in the lattice generated by M (fall-back strategy), substractive case
# S is the list of skew small vectors, fb is incremented at each call to the while loop
def fb_sub(k, c, H, S, M, fb):
    ct = copy(c)
    while ct[k] >= H[k][0]:
        fb[0] = fb[0] + 1
        L = []
        for v in S[k]:
            if k != 0:
                D = CVA(ct - v, M.submatrix(0, 0, k, M.dimensions()[0]))
                for d in D:
                    L.append(ct - v - d)
                    if in_search_space(ct - v - d, H):
                        return ct - v - d
        if len(L) == 0:
            break
        else:
            ct = L[0]
    return vector([h[0] - 1 for h in H])

# Compute relative error. If more elements than expected are reported, return 0
def relative_error(ret, H, M):
    if len(ret) > round(size_H(H) / M.determinant()):
        return 0
    else:
        return (n((round(size_H(H) / M.determinant()) - len(ret)) / round(size_H(H) / M.determinant())) * 100)

# Pack all the functions for the algorithm
# method must be: global_ssv, local_ssv or sparse_ssv
# M is the matrix that represents the lattice
# H is the search space
# l is the level
# bound is the bound for the small linear combination
def gen_sieve(method, M, H, l, bound):
    (V, S) = method(M, H, l, bound)
    rootV = sum([len(v) for v in V])
    rootS = sum([len(v) for v in S])
    fb = [0]
    L = []
    c = vector([0 for k in range(len(H))])
    sieve(len(H) - 1, c, H, V, S, L, l, M, fb)
    ret = remove_duplicate(L)
    for v in ret:
        assert(in_lattice(v, M))
        assert(in_search_space(v, H))

    return (relative_error(ret, H, M), rootV, sum([len(v) for v in V]), rootS, fb[0])

# gen_sieve specialized for globalntv
def global_ntv(M, H, l, bound):
    return gen_sieve(global_ssv, M, H, l, bound)

# gen_sieve specialized for localntv
def local_ntv(M, H, l, bound):
    return gen_sieve(local_ssv, M, H, l, bound)

# gen_sieve specialized for sparsentv
def sparse_ntv(M, H, l, bound):
    return gen_sieve(sparse_ssv, M, H, l, bound)

# Get min, med, max and mean of a list
def get_info(L):
    return (min(L), float(median(L)), max(L), float(mean(L)))

# Extract informations coming from the results of bench (not bench_time*)
# Get min, median, maximum and mean of
#   - relative error
#   - number of nearly transition vectors at the beginning of the algorithm
#   - number of nearly transition vectors at the end of the algorithm
#   - number of skew small vectors at the beginning of the algorithm
#   - number of call to the fall-back strategy
def extract_info(L):
    rel_err = [i[0] for i in L]
    rootVb  = [i[1] for i in L]
    rootVe  = [i[2] for i in L]
    rootS   = [i[3] for i in L]
    fb      = [i[4] for i in L]
    print("Relative error")
    print(get_info(rel_err))
    print("ntvs at beg")
    print(get_info(rootVb))
    print("ntvs at end")
    print(get_info(rootVe))
    print("ssvs at beg")
    print(get_info(rootS))
    print("fb")
    print(get_info(fb))

# Benchmarks
## k: number of random matrices
## l: level
## I: build a t-seach space [-I, I)^(t-1) * [0, I)
## t: dimension of the search space
## A_*: coefficients for the small linear combination, if empty, do not permform the sieve
## seed: modify the seed (default is 42)
def bench(k, l, I, t, A_gtv, A_ltv, A_stv, seed = 42):
    set_random_seed(seed)
    L_gtv = []
    L_ltv = []
    L_stv = []

    H = []
    for i in range(0, t - 1):
        H.append([-I, I])
    H.append([0, I])

    lb = (I*2)^(l)
    gb = (I*2)^(l + 1)

    for i in range(0, k):
        M = gen_matrix(t, random_prime(gb, lbound=lb))
        if len(A_gtv) != 0:
            L_gtv.append(global_ntv(M, H, l, A_gtv))
        if len(A_ltv) != 0:
            L_ltv.append(local_ntv(M, H, l, A_ltv))
        if len(A_stv) != 0:
            L_stv.append(sparse_ntv(M, H, l, A_stv))

    if len(A_gtv) != 0:
        print("----- globalntv -----")
        extract_info(L_gtv)
    if len(A_ltv) != 0:
        print("----- localntv -----")
        extract_info(L_ltv)
    if len(A_stv) != 0:
        print("----- sparsentv -----")
        extract_info(L_stv)

################################################################################
### Specific sparsentv (close to a generalized plane sieve when l=1)
################################################################################

# Specific fall-back startegy (additive case)
def fb_add_spec(k, c, H, S, M, fb):
    ct = copy(c)
    while ct[k] < H[k][1]:
        fb[0] = fb[0] + 1
        L = []
        for v in S[k]:
            if k != 0:
                D = CVA(ct + v, M.submatrix(0, 0, k, M.dimensions()[0]))
                for d in D:
                    L.append(ct + v - d)
                    if in_search_space(ct + v - d, H):
                        return ct + v - d
        if len(L) == 0:
            break
        else:
            ct = L[0]
            if k - 1 > i:
                cp = fb_add_spec(k - 1, ct, H, S, M, fb)
                if in_search_space(cp, H):
                    return cp
                cp = fb_sub_spec(k - 1, ct, H, S, M, fb)
                if in_search_space(cp, H):
                    return cp
    return vector([h[1] for h in H])

# Specific fall-back startegy (substractive case)
def fb_sub_spec(k, c, H, S, M, fb):
    ct = copy(c)
    cp = 0
    while ct[k] >= H[k][0]:
        fb[0] = fb[0] + 1
        L = []
        for v in S[k]:
            if k != 0:
                D = CVA(ct - v, M.submatrix(0, 0, k, M.dimensions()[0]))
                for d in D:
                    L.append(ct - v - d)
                    if in_search_space(ct - v - d, H):
                        return ct - v - d
        if len(L) == 0:
            break
        else:
            ct = L[0]
            if k - 1 > i:
                cp = fb_add_spec(k - 1, ct, H, S, M, fb)
                if in_search_space(cp, H):
                    return cp
                cp = fb_sub_spec(k - 1, ct, H, S, M, fb)
                if in_search_space(cp, H):
                    return cp
    return vector([h[0] - 1 for h in H])

# Add to c a vector of V[k] if possible, repair with S otherwise
def sieve_spec(k, c, H, V, S, L, l, M, fb):
    ct = copy(c)
    while ct[k] < H[k][1]:
        if in_search_space(ct, H):
            L.append(ct)
        if k > 0:
            sieve_spec(k - 1, ct, H, V, S, L, l, M, fb)
        ct = add_spec(k, ct, H, V, S, l, M, fb)
    ct = copy(c)
    ct = sub_spec(k, ct, H, V, S, l, M, fb)
    if in_search_space(ct, H):
        L.append(ct)
    while ct[k] >= H[k][0]:
        if k == 0 and in_search_space(ct, H):
            L.append(ct)
        if k > 0 :
            sieve_spec(k - 1, ct, H, V, S, L, l, M, fb)
        ct = sub_spec(k, ct, H, V, S, l, M, fb)

# Add to c a vector of V[k] if possible, repair with S otherwise
def add_spec(k, c, H, V, S, l, M, fb):
    for v in V[k]:
        if in_extended_search_space(c + v, H, k - 1):
            return c + v
    d = 0
    if k > l or (k == len(H) - 1):
        d = fb_add_spec(k, c, H, S, M, fb)
        if in_search_space(d, H):
            V[k].append(d - c)
            S[k].append(d - c)
            V[k] = sort_by_coordinate(V[k], k)
            S[k] = sort_by_coordinate(S[k], k)
    else:
        d = vector([h[1] for h in H])
    return d

# Subtract to c a vector of V[k] if possible, repair with S otherwise
def sub_spec(k, c, H, V, S, l, M, fb):
    for v in V[k]:
        if in_extended_search_space(c - v, H, k - 1):
            return c - v
    d = 0
    if k > l or (k == len(H) - 1):
        d = fb_sub_spec(k, c, H, S, M, fb)
        if in_search_space(d, H):
            V[k].append(c - d)
            S[k].append(c - d)
            V[k] = sort_by_coordinate(V[k], k)
            S[k] = sort_by_coordinate(S[k], k)
    else:
        d = vector([h[0] - 1 for h in H])
    return d

# Pack all the functions to call the specific sparsentv
def gen_sieve_spec(M, H, l, bound):
    (V, S) = sparse_ssv(M, H, l, bound)
    rootV = sum([len(v) for v in V])
    rootS = sum([len(v) for v in S])
    fb = [0]
    L = []
    c = vector([0 for k in range(len(H))])
    sieve_spec(len(H) - 1, c, H, V, S, L, l, M, fb)
    ret = remove_duplicate(L)
    for v in ret:
        assert(in_lattice(v, M))
        assert(in_search_space(v, H))

    return (relative_error(ret, H, M), rootV, sum([len(v) for v in V]), rootS, fb[0])

# Benchmarks for the running time
# k: number of matrices generated
# I: bound on t-search space ((-I, I), (-I, I), ..., (0, I))
# A_gtv: bound on the coefficient of the linear combination for globalntv
  # e.g.: ((-2, 2), (-2, 2), (-1, 1), (-1, 1))
# A_ltv: bound on the coefficient of the linear combination for localntv
  # e.g.: ((-2, 2), (-2, 2), (-1, 1), (-1, 1))
# seed: set random seed
def bench_time_l2(k, I, t, A_gtv, A_ltv, seed = 42):
    set_random_seed(seed)

    # List that will contain all the matrices we want to use
    L = []

    # Search space
    H = []
    for i in range(0, t - 1):
        H.append([-I, I])
    H.append([0, I])

    # Lower bound for the volume of the lattice
    lb = (I*2)^(2)
    # Larger bound for the volume of the lattice
    gb = (I*2)^(3)

    # Generate and store the matrices
    for i in range(0, k):
        L.append(gen_matrix(t, random_prime(gb, lbound=lb)))

    # Fake generalized plane sieve, since l=1
    time0 = time.time()
    for i in range(0, k):
        # Since l = 1, it is not necessary to define bound in gen_sieve_spec
        gen_sieve_spec(L[i], H, 1, [])
    time1 = time.time()
    time_ps = time1 - time0

    # 2-level globalntv
    time0 = time.time()
    for i in range(0, k):
        global_ntv(L[i], H, 2, A_gtv)
    time1 = time.time()
    time_gtv = time1 - time0

    # 2-level localntv
    time0 = time.time()
    for i in range(0, k):
        local_ntv(L[i], H, 2, A_ltv)
    time1 = time.time()
    time_ltv = time1 - time0

    print("----- 2-level globalntv -----")
    print(time_gtv)
    print("----- 2-level localntv -----")
    print(time_ltv)
    print("----- Plane sieve -----")
    print(time_ps)

# Benchmarks for the running time
# Benchmarks for the running time
# k: number of matrices generated
# I: bound on t-search space ((-I, I), (-I, I), ..., (0, I))
# A_gtv: bound on the coefficient of the linear combination for globalntv
  # e.g.: ((-2, 2), (-2, 2), (-1, 1), (-1, 1))
# A_ltv: bound on the coefficient of the linear combination for localntv
  # e.g.: ((-2, 2), (-2, 2), (-1, 1), (-1, 1))
# seed: set random seed
def bench_time_l3(k, I, t, A_gtv, A_ltv, seed = 42):
    set_random_seed(seed)

    # List that will contain all the matrices we want to use
    L = []

    # Search space
    H = []
    for i in range(0, t - 1):
        H.append([-I, I])
    H.append([0, I])

    # Lower bound for the volume of the lattice
    lb = (I*2)^(3)
    # Larger bound for the volume of the lattice
    gb = size_H(H)

    # Generate and store the matrices
    for i in range(0, k):
        M = gen_matrix(t, random_prime(gb, lbound=lb))
        L.append(M)

    # 3-level globalntv
    time0 = time.time()
    for i in range(0, k):
        global_ntv(L[i], H, 3, A_gtv)
    time1 = time.time()
    time_gtv3 = time1 - time0

    # 2-level localntv
    time0 = time.time()
    for i in range(0, k):
        local_ntv(L[i], H, 2, A_ltv)
    time1 = time.time()
    time_ltv = time1 - time0

    # 3-level localntv
    time0 = time.time()
    for i in range(0, k):
        global_ntv(L[i], H, 2, A_gtv)
    time1 = time.time()
    time_gtv = time1 - time0

    print("----- 2-level globalntv -----")
    print(time_gtv)
    print("----- 2-level localntv -----")
    print(time_ltv)
    print("----- 3-level globalntv -----")
    print(time_gtv3)
