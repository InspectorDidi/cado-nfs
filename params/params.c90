###########################################################################
#     Parameter file for Cado-NFS
###########################################################################

# This file is a sample parameter file for a 91-digit gnfs input

# Anything after a # is a comment, until the end of the line. Any empty line
# is ignored. All quotes in the comments in this file are for emphasis and
# not part of the parameters.

# Each parameter should be on an individual line.
# The parameters form a tree structure. A parameter of the form
#   foo.bar.baz = 42
# is said to have path "foo.bar", key "baz", and value "42".

# Objects of the Python scripts that take parameters from the parameter file
# have a path associated with them; for example, the Sieving task uses path
# "tasks.sieve", and the las siever run in the Sieving task uses
# "tasks.sieve.las". When looking for a parameter, we start at the object's
# path, then work towards to root of the tree until the key is found.
# This means that, in principle, all parameters could be specified without a
# path, so long as no two parameters of the same key with different values
# occur. In this file we specify most parameters will full path to clarify
# which part of the computation they affect.

# Some variable substitution occurs in the values specified in the parameters:
# A string of the form "${FOO}" is substituted by the value of the shell
# environment variable "$FOO".
# A string of the form "$(foo)" is substituted by the value of the parameter
# with key "foo", where the search starts at the path where "$(foo)"
# occurred.

# Some parameters apply to all steps of the algorithm (General parameters
# below), and are related to the execution environment. Some other
# parameters control the many different tunables of the execution of the
# algorithm. Such parameters are relevant to only one of the steps of NFS,
# and are thus listed under the section related to the corresponding
# step. Each of the sections corresponding to one step in particular
# also contains a couple of parameters relative to the execution
# environment (for that step only).

# The cadofactor.py script may be used as:
# cadofactor.py <parametersfile> [<additional parameters> [...]]
# Additional parameters on the command line are specified in the same
# format as in this file, e.g., "foo.bar.baz=42", and override values found
# in the parameter file.

###########################################################################
# General parameters
###########################################################################

# General parameters are relevant to the behaviour of the cadofactor.py script.

# - location and name of files -
name = c90
# All files created by cadofactor will be prefixed by this name.

# N: The number to be factored. This c90 here is given only as an example,
# replace it in this file or override it on the command line
N = 482940676938975075806475467716373950242726509723517010302524110187257004202892794033435637

# Adjust sourcedir to point to the root of your CADO source directory.
# This parameter is not actually used by cadofactor directly, but it is
# referenced as $(sourcedir) further down in this parameter file.
sourcedir=${HOME}/cado-nfs

# Adjust builddir to point to the root of your CADO build directory
# Not used directly, either, but referenced, too.
builddir=${HOME}/build/cado-nfs/

# workdir: the path of the working directory; if a relative path is
# specified, it is relative to the CWD from which cadofactor is run.
# All the output files of sieving, filtering, etc., are stored under the
# working directory.
# Note that there is no need to have the working directory located under
# the CADO source or build directory. In fact, it is advisable to keep it
# separate to facilitate deleting or backing-up the sources, executables,
# and factorization data individually.
tasks.workdir = /tmp/


###########################################################################
# Parameters for Tasks
###########################################################################

# Tasks are the different steps of an NFS factorization: polynomial
# selection, generating the factor base, sieving, etc.

# execpath: Specifies the search path for binary programs that should be run.
# Each binary program that is run can be specified with "execpath",
# "execsubdir", and "execbin" parameters; the script looks for the binary
# executable as "execpath/execsubdir/execbin" and "execpath/execbin", in this
# order. Defaults for these parameters are defined for each program in
# cadoprograms.py; usually it is sufficient to set "execpath".
tasks.execpath=$(builddir)

# verbose: Verbosity of program output. Many programs accept a -v (or
# similar) command line flag; this parameter specifies whether verbose
# output should be enabled. Has no effect on cadofactor itself, just on the
# sub-programs. Cadofactor's own output is controlled by the --screenlog
# command line parameter.
tasks.verbose = 1

# For tasks that use the client/server set-up, currently polynomial selection
# and sieving, set a time-out in seconds after which assigned workunits for
# which no result was returned get cancelled and re-submitted, so that other
# clients can (hopefully) finish them
tasks.wutimeout = 3600 # one hour

# After a total of maxtimedout workunits have timed out, the factorization
# is aborted, as such a large number of timed out workunits may indicate a
# problem with the clients. The default is 100. For large factorization on
# unreliable machines which can be stopped/restarted frequently, this limit
# is probably too small and should be increased.
tasks.maxtimedout = 100

# Various tasks refer to the factor base bounds rlim, alim, and to the
# large prime bounds lpbr, lpba. By adding these value to the root node of
# the parameter tree, all tasks can find them.

# (r,a) means rational or algebraic side
rlim = 270782
alim = 320938
# The number of rational (resp. # algebraic) primes is roughly rlim/log(rlim)
# (resp. alim/log(rlim))
lpbr = 23
lpba = 23
# lpbr/lpba is the (base 2 log of the) large prime bound

###########################################################################
# Polynomial selection task with Kleinjung's algorithm (2008)
###########################################################################

tasks.polyselect.degree = 4		# degree of the algebraic polynomial

tasks.polyselect.threads = 2
    # How many threads to use per polyselect process

tasks.polyselect.P = 10000		# choose lc(g) with two prime factors in [P,2P]
    # Setting a large value will most likely find better polynomials,
    # but the number of found polynomials will be smaller.
    # As a rule of thumb, we want at least 100 found polynomials in total
    # (without norm limitation, see below).

tasks.polyselect.admin = 0          # min value for leading coefficient of f(x)
    # If not set, the default is 0.

tasks.polyselect.admax = 150e3      # max value for leading coefficient of f(x)

tasks.polyselect.incr = 60	    # increment for leading coefficient of f(x)
    # This factor is usually a smooth number, which forces projective roots in
    # the algebraic polynomial. 60 is a good start, 210 is popular as well.
    # Warning: to ensure lc(f) is divisible by incr, admin should be divisible
    # by incr too.

    # The polynomial selection search time is proportional to the
    # length of the search interval, i.e., (admax-admin)/incr.

tasks.polyselect.nrkeep = 40

tasks.polyselect.adrange = 5000		# size of individual tasks
    # Polynomial selection is split into several individual tasks. The
    # complete range from admin to admax has to be covered for the polynomial
    # selection to complete. The number of individual tasks is
    # (polsel_admax-polsel_admin)/polsel_adrange. Each such task is issued as
    # a workunit to a slave for computation.

tasks.polyselect.nq = 256
    # Number of small primes in the leading coefficient of the linear polynomial
    # Safe to leave at the default value
    # Recommended values are powers of the degree, e.g., 625 for degree 5,
    # or 1296 for degree 6. Here 256 = 4^4 thus the leading coefficient of
    # the linear polynomial will be q1*q2*q3*q4*p1*p2 where q1,q2,q3,q4 are
    # small primes, and P <= p1, p2 < 2*P.


###########################################################################
# Sieve task
###########################################################################

tasks.sieve.mfbr = 75
tasks.sieve.mfba = 70
    # mfbr/mfba is the (base 2 log of the) limit for the cofactor we try
    # to split into large primes.

tasks.sieve.rlambda = 2.131250000000000
tasks.sieve.alambda = 2.103125000000000
    # rlambda/alambda is the early-abort ratio: if after sieving, and
    # subtracting from the log of the norm the contribution of the
    # sieved primes, the approximation of the log of the remaining
    # cofactor is larger than lambda times lpb, we reject.
    # Note that this has in particular the effect that if e.g. rlambda <
    # some integer k+1, then at most k large primes are allowed on the
    # rational side. It is customary, when at most k large primes are
    # allowed, to set rlambda to e.g. k + 0.1, in order to compensate for
    # inaccuracies due to sieving.

tasks.sieve.ncurves0 = 4
tasks.sieve.ncurves1 = 2
    # ncurves0 controls the number of P-1/P+1/ECM curves used in the
    # cofactorization on side 0 (i.e., rational side), more precisely we
    # use 3+ncurves0 curves. If one increases ncurves0, one will find more
    # relations, but the cofactorization cost will increase.
    # Same for ncurves1 on side 1 (algebraic side).
    # If unspecified, the number of curves is deduced from the value of lpbr
    # or lpba, see function nb_curves() in file sieve/ecm/facul.c.


tasks.I = 11
    # Sieving range in lattice siever
    # The lattice siever sieves over a range in the (i,j) plane which is
    # 2^I times 2^(I-1), to put things simply (some rescaling may change
    # this, but the size of the sieve area remains constant). Increasing
    # I by 1 multiplies the amount of required RAM for the siever by a
    # factor of 4.
    # Note: now I is used also in the polynomial selection (for the computation
    # of Murphy's E value) thus we define it at the "tasks" level, not at the
    # "tasks.sieve" level.


tasks.sieve.ratq = 0
    # The ratq parameter specifies whether or not the special-q is to be
    # taken on the rational side (ratq=1) or on the algebraic side
    # (ratq=0). ratq should be set on the side where the largest norms are
    # expected. As a very rough rule of thumb, this means ratq=0 for gnfs
    # runs and usually for snfs runs, but ratq=1 for snfs runs where the
    # degree of the polynomial is forced to be small by algebraic factors.

tasks.sieve.qmin = 400000		# Start of the special-q range
    # qmin is usually equal to the corresponding factor base bound, but this
    # is not a requirement - it can be both larger and smaller.

tasks.sieve.qrange = 10000		# The size of an elementary sieving task
    # The sieving process is split into many individual tasks, where each task is
    # assigned as a workunit to a client. This parameter controls the size of
    # individual tasks.

tasks.sieve.threads = 2
    # The lattice siever program las may run in a multithreaded manner.
    # This keeps the amount of memory used constant, and just runs
    # faster.

###########################################################################
# Filtering task
###########################################################################

tasks.filter.purge.keep = 160		# maximal excess wanted after purge
					# (purge shrinks if needed)
tasks.filter.purge.add_ratio = 0.1
    # Number of additional required relations before next filtering step
    # expressed as a ratio of the number of unique relations already collected
    # Default value is 0.1 (i.e. number of additional relation is equal to 10% of number of unique relations)
tasks.filter.maxlevel = 15		# perform up to <maxlevel>-way merges
#tasks.filter.ratio = 1.1		# used only when forbw=0 (see below)
tasks.filter.merge.forbw = 3 # forbw=0: stops the merge when the weight of the
			     #    matrix multiplied by the number of rows c*N
			     #    exceeds ratio*min(c*N)
			     # forbw=1: stops when the product c*N is minimal
			     #    (more exactly when it increases 20 times in
                             #     a row)
			     # forbw=3: stops when the average number of
                             #    non-zero coefficients c/N exceeds coverNmax
                             #    (default 100)
tasks.filter.merge.coverNmax = 100
tasks.filter.purge.required_excess=0.1 # Controls extra sieving:
                                       # completes the filtering only when
                                       # the relative excess (excess divided
                                       # by number of ideals) is larger than
                                       # the given value (default 0.1) after
                                       # all singletons have been removed.
                                       # Setting required_excess=0.0 will
                                       # complete the factorization as soon
                                       # as a positive excess is obtained.

###########################################################################
# Linear algebra and characters tasks
###########################################################################

# - runtime environment -
# cadofactor.py supports only running the linear system solving on the
# host running cadofactor.py itself, using posix threads. More advanced
# usage has to go by hand.
tasks.linalg.bwc.threads = 2x2		# Multithreading level of Block-Wiedemann ; Use
					# <mn> (a single integer) or <m>x<n>; if a single
					# integer is given, a split close to sqrt(mn) is chosen
tasks.linalg.bwc.interval = 100		# checkpointing interval for bwc.
tasks.linalg.bwc.interleaving = 0
tasks.linalg.bwc.m = 64
tasks.linalg.bwc.n = 64
tasks.linalg.bwc.shuffled_product = 1
tasks.linalg.characters.nchar = 50		# number of characters
tasks.linalg.characters.threads = 2

###########################################################################
# Square root task
###########################################################################

# Number of threads used for the square root. Dependencies will be processed
# by blocks of 16 for example. If the number of dependencies is not a multiple
# of say 16, then the last block (if needed) will be reduced to the actual
# number of remaining dependencies.
# tasks.sqrt.threads = 16

# To start again at the first dependency (might be useful in debug mode):
# tasks.sqrt.first_dep = 0

###########################################################################
# Work unit server
###########################################################################

# address: The IP address where the server will listen for incoming
# connections from clients.  The default behavior if not set is to
# listen on all network devices (that is, to listen on the wild-card
# address 0.0.0.0).  If a hostname is given, will call gethostbyname()
# to discover the associated IP address and listen for connections
# only on that interface.  For example, listening on address
# "localhost" will only allow clients running on the same machine to
# connect.  You should not set this explicitly unless you really only
# want to listen on that particular address and interface.

# server.address = localhost

# port: The server of the client/server set-up will listen at this port
# If you want to run several cadofactor servers on the same machine, you
# need to specify a different port for each one.
server.port = 8001


# ssl: whether to use SSL for client/server communication.
# Without SSL authentication and encryption, it is possible for an attacker
# on the same network to modify workunits sent to clients and so effect
# execution of malicious code on the client machines. With SSL, clients
# are started with the server's certificate fingerprint as a command line
# argument, and verify the certificate when first connecting. The
# certificate is then used for all subsequent communication.
# The default is yes.

# server.ssl = yes


# whitelist: a comma separated list of IP ranges that should be allowed to
# contact the server. The IP ranges are given in CIDR format: an IP address,
# optionally followed by a slash and the number of most significant bits
# that need to match. For example, 192.168.0.0/24 means that all IP
# addresses in the range 192.168.0.0, ..., 192.168.0.255 are allowed.
# Here, hostnames can also be used in place of the IP address, their name
# will be resolved to an IP address.
# Note that the hostnames on which cadofactor starts clients, i.e., the
# hostnames in the slaves[...].hostnames parameters, are always added to the
# whitelist. You should have to whitelist addresses manually only if you
# want to start clients manually.

# server.whitelist = 192.168.0.0/24,localhost


###########################################################################
# Worker slaves
###########################################################################

# The cadofactor.py script has the ability to spawn client scripts on many
# machines using ssh, in a master/slave manner. The client scripts then
# request workunits describing a small part of the computation that needs
# to be done, perform this computation, upload the result to the master
# running the cadofactor.py script, then request and process the next
# workunit. Client scripts can be launched manually as well to participate
# in an ongoing factorization.

# Clients which cadofactor.py should start are specified under "slaves".
# We look for any path under "slaves" with a "hostnames" key, then for each
# host name specified (comma separated list, with multiplicity), one slave is
# launched on that host.
# If the "hostnames" value is of the form "@filename", then the host names
# are read from the file "filename", one host name per line, with the same
# multiplicity rule.
# Note: if the host name for a client is "localhost", then the client is
# started directly as sub-processes of the cadofactor script; if it is not
# "localhost", then clients are started through SSH. This affects the
# client's current working directory: if the client is started as a
# sub-process, its CWD is the same as that of the cadofactor script; if it
# is started through SSH, its CWD is the CWD after an SSH login (usually the
# user's home directory).

slaves.hostnames = localhost

# Example with multiple host names. This launches one client on localhost,
# two on otherhost1, and one on otherhost2, assuming there is no nrclients
# parameter (see below) that would override the multiplicity
# slaves.hostnames = localhost, otherhost1, otherhost1, otherhost2

# Modifies the behaviour of the "hostnames" list: if nrclients is specified,
# then multiplicity in the "hostnames" list is ignored, and "nrclients" client
# scripts are launched on each unique host name.

slaves.nrclients = 2

# scriptpath: The path to the wuclient2.py scripts, on the slave's file
# system.

# scriptpath must point to the directory in which the wuclient2.py script
# can be found on the client machines. I.e., with scriptpath as set in this
# example and if, for example, "sourcedir = /tmp/cado-nfs", then clients will
# be started through:
# "ssh [hostname] /tmp/cado-nfs/scripts/cadofactor/wuclient2.py [client parameters]"
slaves.scriptpath = $(sourcedir)/scripts/cadofactor

# downloadretry: Number of seconds a client should wait between failed
# download attempts from the server

slaves.downloadretry = 10

# This sets the posix ``nice level'' for programs launched by a slave.
# If you don't know what it is, you may leave as is, or set to 0.

slaves.niceness = 10		# nice level for the sieving jobs

# basepath: defines the base directory under which wuclient creates its
# download and working directories. It is permissible to let all clients of
# the same factorization use the same download directory; files are
# protected by locking to prevent download races. If the download directory
# is on a shared file system, then this filesystem must support locking.
# The working directories should be unique; the default choice for the
# working directory includes the clientid which should ensure uniqueness.

# Since this example runs its slaves on localhost, we use a subdirectory
# of the cadofactor.py working directory, so that all files of both master
# and clients can be cleaned up easily.
slaves.basepath = /tmp/c90.wuclients

# If you want to launch clients on multiple groups of slave machines, with
# different parameters per group, you can group them by different parameter
# paths, like so:
# slaves.downloadretry = 10
# slaves.basepath = /tmp/wuclient
# slaves.home.hostnames = localhost
# slaves.home.nrclients = 1
# slaves.home.scriptpath = $(sourcedir)/scripts/cadofactor
# slaves.work.desktop.hostnames = workstation1, workstation2
# slaves.work.desktop.scriptpath = /path/to/scripts/cadofactor
# slaves.work.cluster.hostnames = clusternode1, clusternode2, clusternode3
# slaves.work.cluster.scriptpath = /other/path/to/scripts/cadofactor
## Use 4 slaves on all "work" slaves, both "desktop" and "cluster"
# slaves.work.nrclients = 4

# Here, "home", "work", "desktop", and "cluster" are arbitrary alphanumeric
# strings; their sole purpose is to create different nodes in the parameter
# tree under which hosts that should use the same parameters can be grouped.
